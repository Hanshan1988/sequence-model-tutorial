{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d692cc8e-c80b-432e-b994-ca6917333210",
   "metadata": {},
   "source": [
    "# Basic Supervised Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d3b11-c0bd-46fb-a9b2-c6749a7baa86",
   "metadata": {},
   "source": [
    "## Import Pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f950c04a-2788-4f3c-b1db-20a3cf97dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from d2l import tensorflow as d2l_tf\n",
    "from d2l import torch as d2l_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "771b5455-3d51-4e34-90be-ef7ce412fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2689cb2-125c-471c-9d46-005931f4a592",
   "metadata": {},
   "source": [
    "* https://www.tensorflow.org/tutorials/keras/regression\n",
    "* https://adamoudad.github.io/posts/keras_torch_comparison/syntax/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdee1e3-cba0-46bd-94d8-f1dbcbc96c7e",
   "metadata": {},
   "source": [
    "## Problem - Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19aef35-cc38-4373-bb4c-853270f4a4d8",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec22c2f3-8cc3-43f2-95df-b3e32e28ed42",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.03\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "INIT_STDDEV = 0.01 # random initialisation from normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1c876-dbb8-4f59-b313-bd09a524752c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a48c5ea-1b01-46a5-804d-ebcb14cb19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = tf.constant([2.0, -3.0])\n",
    "true_b = 4.0\n",
    "features, labels = d2l_tf.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad4cf31-233a-462e-b33f-9cb44f86e261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 2), dtype=float32, numpy=\n",
       " array([[ 0.25883058,  2.0530121 ],\n",
       "        [ 0.39729354, -1.0603833 ],\n",
       "        [ 0.05721881, -0.73641664],\n",
       "        [ 0.31468382, -1.043708  ],\n",
       "        [-1.0798566 , -0.550977  ],\n",
       "        [-1.6296045 ,  2.189807  ],\n",
       "        [ 0.3019283 , -0.8288437 ],\n",
       "        [-0.3030514 ,  0.40066257]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       " array([[-1.6477871],\n",
       "        [ 7.9544015],\n",
       "        [ 6.3242235],\n",
       "        [ 7.7690415],\n",
       "        [ 3.4966393],\n",
       "        [-5.8354015],\n",
       "        [ 7.093859 ],\n",
       "        [ 2.1846747]], dtype=float32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:BATCH_SIZE], labels[:BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a921ba1c-a51d-41e3-a429-e85129bf4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array_tf(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a TensorFlow data iterator.\"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(data_arrays)\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b706b9f5-ef2d-468b-9ccb-e19a66aba2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "data_iter = load_array_tf((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "189664c0-1021-46a5-9a5b-24c6fe5e3d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 2), dtype=float32, numpy=\n",
       " array([[ 1.1484678 , -0.08717881],\n",
       "        [-0.47707787,  1.4168806 ],\n",
       "        [-0.58437693, -0.66772157],\n",
       "        [-0.6238647 ,  0.85288274],\n",
       "        [ 0.8883182 ,  0.2856394 ],\n",
       "        [-1.4484255 ,  0.34251413],\n",
       "        [ 0.35963306,  0.7526962 ],\n",
       "        [ 0.6157805 , -0.04350418]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 1), dtype=float32, numpy=\n",
       " array([[ 6.548785  ],\n",
       "        [-1.1996217 ],\n",
       "        [ 4.844516  ],\n",
       "        [ 0.19433065],\n",
       "        [ 4.9166293 ],\n",
       "        [ 0.07303171],\n",
       "        [ 2.4524748 ],\n",
       "        [ 5.358545  ]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a0cab3-923e-4081-afca-68076f889488",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "352e9ba6-e40d-4458-b235-476163311206",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2.0, -3.0])\n",
    "true_b = 4.0\n",
    "features, labels = d2l_torch.synthetic_data(true_w, true_b, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b663559-f0c6-4300-a829-ef0c9d1cb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9355, -0.8222],\n",
       "         [-0.5997,  1.0499],\n",
       "         [-0.9472,  0.2633],\n",
       "         [ 0.9309,  0.4007],\n",
       "         [-1.2002,  0.6576],\n",
       "         [-0.3912,  0.0140],\n",
       "         [ 0.0821, -0.7032],\n",
       "         [ 0.5781,  0.5491]]),\n",
       " tensor([[ 8.3278],\n",
       "         [-0.3404],\n",
       "         [ 1.3197],\n",
       "         [ 4.6700],\n",
       "         [-0.3835],\n",
       "         [ 3.1698],\n",
       "         [ 6.2808],\n",
       "         [ 3.5099]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[:BATCH_SIZE], labels[:BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6904357f-9d6a-46fa-b7ad-1556e03dbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array_pt(data_arrays, batch_size, is_train=True):  #@save\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c755857d-fd2c-4c0c-846c-6c1cc34b3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = load_array_pt((features, labels), BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06094160-160e-4ecf-a4e4-f4782ee44d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 2.0036,  0.4265],\n",
       "         [-0.2566, -0.3797],\n",
       "         [-0.3721, -0.6596],\n",
       "         [ 0.6673,  0.2818],\n",
       "         [-0.5474,  0.9549],\n",
       "         [-0.1003, -0.0773],\n",
       "         [ 0.5441,  0.1022],\n",
       "         [ 1.7986, -0.4563]]),\n",
       " tensor([[6.7299],\n",
       "         [4.6268],\n",
       "         [5.2592],\n",
       "         [4.4811],\n",
       "         [0.0342],\n",
       "         [4.0300],\n",
       "         [4.7813],\n",
       "         [8.9633]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d664979-c834-44ec-af58-95d99fff1e1c",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b4def-cfae-4b7b-8b7b-80914ff81b39",
   "metadata": {},
   "source": [
    "#### TF Keras Sequential API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b54257-d9d9-4c97-ae12-88e57f26a3be",
   "metadata": {},
   "source": [
    "Need to rerun tensorflow data prep part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78d19303-3287-4432-9019-de8adf52867d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfdb05e1-5df7-4ff6-ba98-2d3c45fd8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.initializers.RandomNormal(stddev=INIT_STDDEV)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021b138-faca-4c01-8efb-bf31eeb496be",
   "metadata": {},
   "source": [
    "**A. Model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99e158bf-45ce-47cb-8752-f7c5d5ffcec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(2, ), name='input'),\n",
    "    tf.keras.layers.Dense(1, activation='linear', \n",
    "                          kernel_initializer=initializer,\n",
    "                          name='dense')\n",
    "])\n",
    "\n",
    "# # Alternatively\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.InputLayer(input_shape=(2, ))\n",
    "# model.add(tf.keras.layers.Dense(1, kernel_initializer=initializer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32d30ded-aa48-4d75-b884-b4fbdda82e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f763b5-8aa4-4b61-82a1-709cec928f99",
   "metadata": {},
   "source": [
    "* The input layer can be ommited here and model can be fitted on input data at a later stage. This way however, `model.summary()` can only be called later when the input data shape is known to the object.\n",
    "* Any types of feature preprocessing e.g. normalisation (`tf.keras.layers.Normalization`) can also be included in the sequential steps as the initial layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27f4ac-4189-4df8-a2d7-5bf3ecd6e2a4",
   "metadata": {},
   "source": [
    "**A. Training process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e3632de-5108-4a7a-b49d-2496ec599855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, features, labels, batch_size, loss, num_epochs, optimizer):\n",
    "    data_iter = load_array((features, labels), batch_size)\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in data_iter:\n",
    "            with tf.GradientTape() as tape:\n",
    "                l = loss(model(X, training=True), y)\n",
    "            grads = tape.gradient(l, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        l = loss(model(features), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46aed491-06d7-4680-9475-c9d2b75bd59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000106\n",
      "epoch 2, loss 0.000095\n",
      "epoch 3, loss 0.000096\n",
      "epoch 4, loss 0.000096\n",
      "epoch 5, loss 0.000096\n"
     ]
    }
   ],
   "source": [
    "train(model, features, labels, BATCH_SIZE, loss, NUM_EPOCHS, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d35209-0c2b-408b-a992-762e1644ab81",
   "metadata": {},
   "source": [
    "**B. Model architecture (Repeated)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4c085de-7262-4f73-9360-cc587e8f410f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(1, activation='linear', \n",
    "                        kernel_initializer=initializer)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf0398-424c-4b4c-aa6c-4c9404deb679",
   "metadata": {},
   "source": [
    "* Here we didn't define the input layer so naturally we cannot call `model.summary()` as the object doesn't know anything about the shape of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6369c-7259-4af6-959d-269f355f0f05",
   "metadata": {},
   "source": [
    "**B. Compile model then train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876a56f-9c14-40e9-9e8e-aed6436b48c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['mse', rmse])\n",
    "model.fit(data_iter,\n",
    "          epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ab016-ca5a-437a-9c23-0be429b2ebeb",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d43d48a-0f84-4088-922b-37c672ed321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in estimating w tf.Tensor([0.00014162 0.00013518], shape=(2,), dtype=float32)\n",
      "error in estimating b [0.00060081]\n"
     ]
    }
   ],
   "source": [
    "w = model.get_weights()[0]\n",
    "print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n",
    "b = model.get_weights()[1]\n",
    "print('error in estimating b', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd1508f-9bd1-4d1b-81f1-b7b5f85d7a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9998584]\n",
      " [-3.4001353]]\n",
      "[4.199399]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c79b54-7062-4c1a-9b2c-eea7b41d540f",
   "metadata": {},
   "source": [
    "#### TF Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42b59bc1-3bb7-4c2e-abf0-0c2977a72736",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2,))\n",
    "# x = tf.keras.layers.Dense(10, activation=\"relu\")(inputs)\n",
    "outputs = tf.keras.layers.Dense(1)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebbc4b9d-b777-4cb6-9eaf-7af6e19b9e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 3\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"linear_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec4e60d8-6227-487f-98f3-75b8b8befa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 39/100 [==========>...................] - ETA: 0s - loss: 8.6179 - mse: 8.6179 - rmse: 2.2938  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 18:42:05.860737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 4ms/step - loss: 3.3768 - mse: 3.3768 - rmse: 0.9626\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.0781e-04 - mse: 1.0781e-04 - rmse: 0.0101\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.0195e-04 - mse: 1.0195e-04 - rmse: 0.0098\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.0211e-04 - mse: 1.0211e-04 - rmse: 0.0098\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 1.0137e-04 - mse: 1.0137e-04 - rmse: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167f08520>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['mse', rmse])\n",
    "model.fit(data_iter,\n",
    "          epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e410501f-e72c-4b22-94c4-6113f5fe1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in estimating w tf.Tensor([1.8048286e-04 4.8398972e-05], shape=(2,), dtype=float32)\n",
      "error in estimating b [-0.00080442]\n"
     ]
    }
   ],
   "source": [
    "w = model.get_weights()[0]\n",
    "print('error in estimating w', true_w - tf.reshape(w, true_w.shape))\n",
    "b = model.get_weights()[1]\n",
    "print('error in estimating b', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4779ee6-63c4-403a-8a87-4cbbd938e594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9998195]\n",
      " [-3.4000485]]\n",
      "[4.200804]\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef760b7-d0cf-4f63-8ec4-879d68a287a8",
   "metadata": {},
   "source": [
    "#### Pytorch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ec337-ad0d-43d7-9de9-28c7924a1a9f",
   "metadata": {},
   "source": [
    "References\n",
    "* https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "* https://medium.com/biaslyai/pytorch-linear-and-logistic-regression-models-5c5f0da2cb9\n",
    "* https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0675c2-180b-4e60-8ac5-ebd217fabd9b",
   "metadata": {},
   "source": [
    "Need to rerun Pytorch data prep part first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a62b69-b154-4ada-916e-918ee25cba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d123100-ecc8-4c1d-9b4a-2bd0858f02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=INIT_STDDEV)\n",
    "\n",
    "model.apply(init_weights)\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c8e241-3896-4f9c-a87b-1ff975112394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iter, loss, num_epochs, optimizer:\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            l = loss(model(X) ,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "        l = loss(model(features), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33fa60eb-3aaa-4d0b-9cee-ac897390f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000114\n",
      "epoch 2, loss 0.000104\n",
      "epoch 3, loss 0.000104\n",
      "epoch 4, loss 0.000104\n",
      "epoch 5, loss 0.000104\n"
     ]
    }
   ],
   "source": [
    "train(model, data_iter, loss, NUM_EPOCHS, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fdb552e-2a72-4807-ae25-cee9557c9508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in estimating w: tensor([0.0002, 0.0007])\n",
      "error in estimating b: tensor([0.0005])\n"
     ]
    }
   ],
   "source": [
    "w = model[0].weight.data\n",
    "print('error in estimating w:', true_w - w.reshape(true_w.shape))\n",
    "b = model[0].bias.data\n",
    "print('error in estimating b:', true_b - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "258509ac-d82c-4a02-b1c2-79e2fcc1b0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9998, -3.0007]])\n",
      "tensor([3.9995])\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3034d-1bc6-4d5f-a39c-0760adaf665b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
